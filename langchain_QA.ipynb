{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- [llama2+langchain](https://zhuanlan.zhihu.com/p/652172969)\n",
    "- [RAG QA](https://python.langchain.com/docs/use_cases/question_answering/)\n",
    "- [langchain vector embedding database](https://ithelp.ithome.com.tw/articles/10327164)\n",
    "- [LangChain: LLM RAG & Agents](https://zhuanlan.zhihu.com/p/654662274)\n",
    "- [LLM Powered Autonomous Agents](https://lilianweng.github.io/posts/2023-06-23-agent/)\n",
    "- [dspy](https://github.com/stanfordnlp/dspy)\n",
    "- [LangChain Installation](https://ithelp.ithome.com.tw/articles/10318758)\n",
    "\n",
    "\n",
    "- [Pipe package github](https://github.com/JulienPalard/Pipe)\n",
    "- [numexpr package github](https://github.com/pydata/numexpr)\n",
    "\n",
    "- [llama2+langchain chat](https://blog.futuresmart.ai/integrating-llama-2-with-hugging-face-and-langchain)\n",
    "- [chroma vector db api](https://docs.trychroma.com/api-reference)\n",
    "- [chroma vector db embeddings](https://docs.trychroma.com/embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAPER\n",
    "\n",
    "- [StoryQA](https://knowledge-nlp.github.io/aaai2023/papers/017-StoryQA-poster.pdf)\n",
    "- [DSPy](https://arxiv.org/pdf/2310.03714.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "- from langchain.agents import load_tools ?\n",
    "- wikipedia ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install huggingface_hub tensorboard langchain sentence_transformers\n",
    "# !pip install wikipedia\n",
    "# !pip install numexpr\n",
    "# !pip install sentence_transformers\n",
    "\n",
    "# # !pip install langchain\n",
    "# !pip install huggingface_hub\n",
    "# !pip install wikipedia\n",
    "# !pip install numexpr\n",
    "# !pip install sentence_transformers\n",
    "\n",
    "# !pip install openai==0.28.1\n",
    "# !pip install Chromadb\n",
    "# !pip install -U openai\n",
    "\n",
    "\n",
    "# !pip install InstructorEmbedding\n",
    "# !pip install sentence_transformers\n",
    "# !pip install Chromadb\n",
    "\n",
    "# !pip install accelerate\n",
    "# !pip install bitsandbytes\n",
    "# !pip install llama-cpp-python\n",
    "\n",
    "\n",
    "# # !pip install openai==0.28.1\n",
    "# !pip install langchain openai chromadb langchainhub\n",
    "\n",
    "\n",
    "\n",
    "# !pip uninstall openai\n",
    "# !pip install typing-extensions\n",
    "# !pip install protobuf\n",
    "# !pip install --upgrade protobuf\n",
    "# !pip install transformers sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "import inspect\n",
    "import wikipedia\n",
    "import re\n",
    "\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open('../../../../secrets/openai_chat_secret.txt', 'r') as f:\n",
    "    # openai.api_key = f.read()\n",
    "    os.environ[\"OPENAI_API_KEY\"] = f.read()\n",
    "\n",
    "with open('../../../../secrets/huggingface_hub_secret.txt', 'r') as f:\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Colorful Toe Treads.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = OpenAI(temperature=0.9)  # model_name=\"text-davinci-003\"\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# web_loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "\n",
    "# Document Loader\n",
    "from langchain.document_loaders import TextLoader\n",
    "text_loader = TextLoader('./books/The Dandelion Girl.txt')\n",
    "# documents = loader.load()\n",
    "\n",
    "\n",
    "# PDF Loader\n",
    "# pdf_file_path = \"./finance.pdf\"\n",
    "# from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# pdf_loader = PyPDFLoader(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "# Split documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "loader = text_loader\n",
    "splitted_docs = text_splitter.split_documents(loader.load())\n",
    "print(len(splitted_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benve\\anaconda3\\envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "'''\n",
    "<https://huggingface.co/shibing624/text2vec-base-chinese/tree/main>\n",
    "model_id: shibing624/text2vec-base-chinese\n",
    "'''\n",
    "# chinese_embedding_name = \"/mnt/h/text2vec-base-chinese\"\n",
    "# chinese_embedding_name = \"shibing624/text2vec-base-chinese\"\n",
    "\n",
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=chinese_embedding_name,\n",
    "#     model_kwargs={\"device\": \"cuda\"},\n",
    "# )\n",
    "\n",
    "\n",
    "embedding_model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_id,\n",
    "    model_kwargs={\"device\": \"cuda\"},\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 384\n"
     ]
    }
   ],
   "source": [
    "splitted_doc_embeddings = embedding_model.embed_documents([doc.page_content for doc in splitted_docs])\n",
    "\n",
    "print(len(splitted_doc_embeddings), len(splitted_doc_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.api.types import Documents, EmbeddingFunction, Embeddings\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ChromadbEmbeddingFunction(EmbeddingFunction):\n",
    "    def __init__(self, embedding_model: EmbeddingFunction):\n",
    "        super().__init__()\n",
    "        self.embedding_model = embedding_model\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        # embeddings = [self.embedding_model.embed_query(x) for x in input]\n",
    "        embeddings = self.embedding_model.embed_documents(input)\n",
    "        return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "her name, to elude the time police. No wonder she had never wanted her picture taken! And how\n",
      "terrified she must have been on that long-ago day when she had stepped timidly into his office to\n",
      "apply for a job! All alone in a strange generation, not knowing for sure whether her father's\n",
      "concept of time was valid, not knowing for sure whether the man who would love her in his\n",
      "-11-\n",
      "forties would feel the same way toward her in his twenties. She had come back all right, just as\n",
      "\n",
      "-8-\n",
      "much as looked at another woman, and here in the space of less than a week he had not only\n",
      "looked at one but had fallen in love with her.\n",
      "Hope was dead in him when he climbed the hill on the fourth day—and then suddenly\n",
      "alive again when he saw her standing in the sun. She was wearing a black dress this time, and he\n",
      "should have guessed the reason for her absence; but he didn't—not till he came up to her and saw\n",
      "\n",
      "\"I'm Julie,\" she said. \"Julie Danvers.\"\n",
      "The name suited her. The same way the white dress suited her—the way the blue sky\n",
      "suited her, and the hill and the September wind. Probably she lived in the little hamlet in the\n",
      "woods, but it did not really matter. If she wanted to pretend she was from the future, it was all\n",
      "right with him. All that really mattered was the way he had felt when he had first seen her, and\n",
      "\n",
      "He returned the book to the shelf and went out and stood on the rustic porch and filled\n",
      "and lighted his pipe. He forced himself to think of Anne, and presently her face came into\n",
      "focus—the firm but gentle chin, the warm and compassionate eyes with that odd hint of fear in\n",
      "them that he had never been able to analyze, the still-soft cheeks, the gentle smile—and each\n",
      "attribute was made more compelling by the memory of her vibrant light brown hair and her tall,\n",
      "\n",
      "long and slender legs. In any event, he got the definite impression that she had somehow stepped\n",
      "out of the past and into the present; and that was odd, because as things turned out, it wasn't the\n",
      "past she had stepped out of, but the future.\n",
      "He paused some distance behind her, breathing hard from the climb. She had not seen\n",
      "him yet, and he wondered how he could apprise her of his presence without alarming her. While\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "collection_name = 'llama2_demo'\n",
    "\n",
    "\n",
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.Client()\n",
    "\n",
    "exist_collection_name_list = [x.name for x in client.list_collections()]\n",
    "# client.reset() \n",
    "for collection_name in exist_collection_name_list:\n",
    "    client.delete_collection(collection_name)\n",
    "\n",
    "collection = client.get_or_create_collection(collection_name, embedding_function=ChromadbEmbeddingFunction(embedding_model))\n",
    "\n",
    "# Add docs to the collection. Can also update and delete. Row-based API coming soon!\n",
    "collection.add(\n",
    "    # embeddings=splitted_doc_embeddings, # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    documents=[doc.page_content for doc in splitted_docs], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    # metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # filter on these!\n",
    "    ids=[f\"dd{i:05d}\" for i in range(len(splitted_doc_embeddings))], # unique for each doc\n",
    "    # ids=[\"f1\", \"f2\"], # unique for each doc\n",
    ")\n",
    "\n",
    "\n",
    "# # Query/search 2 most similar results. You can also .get by id\n",
    "results = collection.query(\n",
    "    query_texts=[\"who is the woman?\"],\n",
    "    n_results=5,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")\n",
    "# print(results)\n",
    "distance_score = results['distances']\n",
    "retrieved_documents = results['documents']\n",
    "# print(distance_score)\n",
    "# print(len(retrieved_documents[0]))\n",
    "for doc in retrieved_documents[0]:\n",
    "    print(doc)\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# template2 = \"\"\"Answer the question based on the following context as well as \n",
    "#                 choosing the actions if you need more reasoning steps or information:\n",
    "\n",
    "# {context}\n",
    "\n",
    "# Action: [\"Want to know more\", \"Answer found\"]\n",
    "\n",
    "# Question: {question}\n",
    "# \"\"\"\n",
    "template2 = \"\"\"Answer the question based on the following context as well as \n",
    "                choosing the actions, \n",
    "                \n",
    "\n",
    "{context}\n",
    "\n",
    "Action: [\"Want to know more\", \"Respond that is certain\"]\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "repond in the following format:\n",
    "    Action: \n",
    "    Respond:\n",
    "    Potential Answer:\n",
    "    Follow-up questions (>= 3):\n",
    "\"\"\"\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt = ChatPromptTemplate.from_template(template2)\n",
    "model = ChatOpenAI()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "\n",
    "retriever_collected_docs = []\n",
    "def retriever_func(question):\n",
    "    global retriever_collected_docs\n",
    "    results = collection.query(\n",
    "        # query_texts=[\"who is the woman?\"],\n",
    "        query_texts=[question],\n",
    "        n_results=5,\n",
    "        # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "        # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    "    )\n",
    "    # print(results)\n",
    "    distance_score = results['distances']\n",
    "    retrieved_documents = results['documents']\n",
    "    \n",
    "    distance_score = results['distances']\n",
    "    retrieved_documents = results['documents']\n",
    "    # print(distance_score)\n",
    "    # print(len(retrieved_documents[0]))\n",
    "    # retriever_collected_docs = []\n",
    "\n",
    "    for doc in retrieved_documents[0]:\n",
    "        retriever_collected_docs.append(doc)\n",
    "        # print(doc)\n",
    "        # print()\n",
    "    return retrieved_documents\n",
    "    \n",
    "\n",
    "chain_asking_question = (\n",
    "    # {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    {\"context\": retriever_func, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    # | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Action: Respond that is certain\\nRespond: The man is infatuated with the girl he met on the hilltop.\\nPotential Answer: The man is deeply captivated by the girl he met on the hilltop. He finds her appearance and presence to be enchanting, and he feels a strong connection to her.\\n\\nFollow-up questions:\\n1. What are some specific details that indicate the man is infatuated with the girl?\\n2. How does the man's infatuation affect his daily life?\\n3. Does the man have any doubts or reservations about his feelings for the girl?\")"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chain_asking_question.invoke(\"What did the president say about technology?\")\n",
    "# chain_asking_question.invoke(\"What are main character's name? think it step by step\")\n",
    "# chain_asking_question.invoke(\"Who are main characters? think it step by step\")\n",
    "# chain_asking_question.invoke(\"What are characters' name? think it step by step\")\n",
    "\n",
    "# Direct asking\n",
    "# chain_asking_question.invoke(\"Who does Randolph talk to?\")\n",
    "# chain_asking_question.invoke(\"Who does Mark talk to? Tell me her name.\") # with instructions\n",
    "\n",
    "# # Summarization\n",
    "# chain_asking_question.invoke(\"What is the main idea of the article?\")\n",
    "\n",
    "\n",
    "# # Abstract idea / Emotional / Opinion\n",
    "chain_asking_question.invoke(\"How does the man feel about the girl she meet on the hill top?\")\n",
    "\n",
    "\n",
    "# #  Indirect question / long-hopping question\n",
    "# chain_asking_question.invoke(\"Who does Mark talk to?\")\n",
    "# chain_asking_question.invoke(\"What is the relationship between the girl Mark talked to on the hill and his wife?\")\n",
    "# chain_asking_question.invoke(\"Find out the relationship between the girl Mark talked to on the hill and his wife.\")\n",
    "\n",
    "# # frequency / Quantity\n",
    "# chain_asking_question.invoke(\"What is the most frequent sentences in the article?\")\n",
    "# chain_asking_question.invoke(\"What is the representative sentences in the story talked by the girl?\") \n",
    "# # the day before yesterday I saw a rabbit, and yesterday I saw a deer, and today, I saw you.\n",
    "\n",
    "# # Ambiguous (Need Clarification)\n",
    "# chain_asking_question.invoke(\"Who is Tom?\") ## many Tom in different stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandelion_girl_questions = []\n",
    "with open(\"TheDandelionGirlQuestion.txt\", \"r\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        dandelion_girl_questions.append(line)\n",
    "        line = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dandelion_girl_0_hop__question_chain_listxd  = []\n",
    "dandelion_girl_2_hop__question_chain_listxd  = []\n",
    "\n",
    "dandelion_girl_0_hop__gathered_docs_list2d = []\n",
    "dandelion_girl_2_hop__gathered_docs_list2d = []\n",
    "\n",
    "dandelion_girl_0_hop__response_list2d = []\n",
    "dandelion_girl_2_hop__response_list2d = []\n",
    "\n",
    "dandelion_girl_0_hop__potential_answer_listxd = []\n",
    "dandelion_girl_2_hop__potential_answer_listxd = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(retriever_collected_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['routine had caught up to him, and he had taken off into the woods without purpose or direction\\nand finally he had come to the hill and had climbed it and seen the girl.\\nHer eyes were blue, he saw when he came up to her—as blue as the sky that framed her\\nslender silhouette. Her face was oval and young and soft and sweet. It evoked a déjà vu so\\npoignant that he had to resist an impulse to reach out and touch her wind-kissed cheek; and even', 'that she loved him, that in a few short hours he would see her again. Surely even a run-down\\ntime machine should have no trouble transporting her from the hamlet to the hill.\\nHe arrived there early and sat down on the granite bench and waited for her to come out\\nof the woods and climb the slope. He could feel the hammering of his heart and he knew that his\\nhands were trembling. Day before yesterday I saw a rabbit, and yesterday a deer, and today,\\nyou.', 'The next afternoon she did not show up either. Nor the next. He could neither eat nor\\nsleep. Fishing palled on him. He could no longer read. And all the while, he hated himself—\\nhated himself for behaving like a lovesick schoolboy, for reacting just like any other fool in his\\nforties to a pretty face and a pair of pretty legs. Up until a few days ago he had never even so\\n-8-\\nmuch as looked at another woman, and here in the space of less than a week he had not only', \"long and slender legs. In any event, he got the definite impression that she had somehow stepped\\nout of the past and into the present; and that was odd, because as things turned out, it wasn't the\\npast she had stepped out of, but the future.\\nHe paused some distance behind her, breathing hard from the climb. She had not seen\\nhim yet, and he wondered how he could apprise her of his presence without alarming her. While\", 'she who asked, \"Will you be here tomorrow?\"—though only because she stole the question from\\nhis lips—and the words sang in his ears all the way back through the woods to the cabin and\\nlulled him to sleep after an evening spent with his pipe on the porch.\\nNext afternoon when he climbed the hill it was empty. At first his disappointment\\nnumbed him, and then he thought, “She\\'s late, that\\'s all”. She\\'ll probably show up any minute.', 'from the well-stocked bookcase by the fireplace, he sat down and thumbed through it to\\nAfternoon on a Hill. He read the treasured poem three times, and each time he read it he saw her\\nstanding there in the sun, her hair dancing in the wind, her dress swirling like gentle snow around\\nher long and lovely legs; and a lump came into his throat, and he could not swallow.\\nHe returned the book to the shelf and went out and stood on the rustic porch and filled', \"pronounced.\\nHe began driving into the country Sunday afternoons and visiting the hilltop. The woods\\nwere golden now, and the sky was even bluer than it had been a month ago. For hours he sat on\\nthe granite bench, staring at the spot where she had disappeared. Day before yesterday I saw a\\nrabbit, and yesterday a deer, and today, you.\\nThen, on a rainy night in mid-November, he found the suitcase. It was Anne's, and he\", \"timidly before his desk. It was inconceivable that a mere twenty years later he could be looking\\nforward eagerly to a tryst with an overimaginative girl who was young enough to be his\\ndaughter. Well, he wasn't—not really. He had been momentarily swayed—that was all. For a\\nmoment his emotional equilibrium had deserted him, and he had staggered. Now his feet were\\nback under him where they belonged, and the world had returned to its sane and sensible orbit.\", 'him someday, about Anne\\'s phobia about cameras and how she had refused to have her picture\\ntaken on their wedding day and had gone on refusing ever since, about the grand time the three\\nof them had had on the camping trip they\\'d gone on last summer.\\nWhen he had finished, she said, \"What a wonderful family life you have. Nineteen-sixtyone must be a marvelous year in which to live!\"\\n\"With a time machine at your disposal, you can move here any time you like.\"\\n-6-', \"him when he went to bed. This time he didn't even try to think of Anne; he knew it would do no\\ngood. Instead he lay there in the darkness and played host to whatever random thoughts came\\nalong—and all of them concerned a September hilltop and a girl with dandelion-colored hair.\\nDay before yesterday I saw a rabbit, and yesterday a deer, and today, you.\\nNext morning he drove over to the hamlet and checked at the post office to see if he had\"]\n"
     ]
    }
   ],
   "source": [
    "questions = dandelion_girl_questions[1:2]\n",
    "for q in questions:\n",
    "\n",
    "    response = chain_asking_question.invoke(q)\n",
    "\n",
    "    dandelion_girl_0_hop__response_list2d.append(response)\n",
    "    print(retriever_collected_docs)\n",
    "    dandelion_girl_0_hop__gathered_docs_list2d.append(retriever_collected_docs)\n",
    "    retriever_collected_docs = []\n",
    "    \n",
    "    resp_parsed = re.split(r\"([\\w \\-\\(\\)>=3]+:)\", response.content)\n",
    "\n",
    "    assert (resp_parsed[1] == \"Action:\" and \n",
    "            resp_parsed[3] == \"Respond:\" and \n",
    "            resp_parsed[5] == \"Potential Answer:\" and \n",
    "            (resp_parsed[7] == \"Follow-up questions:\" or\n",
    "             resp_parsed[7] == \"Follow-up questions (>= 3):\"\n",
    "             )\n",
    "        )\n",
    "    \n",
    "    action = resp_parsed[2].strip()\n",
    "\n",
    "    \n",
    "    action = resp_parsed[2].strip()\n",
    "    respond = resp_parsed[4].strip()\n",
    "    potential_answer = resp_parsed[6].strip()\n",
    "    follow_up_questions = resp_parsed[8].strip().split(\"\\n\")\n",
    "\n",
    "    dandelion_girl_0_hop__potential_answer_listxd.append(potential_answer)\n",
    "\n",
    "    list_of_follow_up_questions = []\n",
    "    for q in follow_up_questions:\n",
    "        if q.strip() != \"\":\n",
    "            list_of_follow_up_questions.append(q.strip())\n",
    "    dandelion_girl_0_hop__question_chain_listxd.append(list_of_follow_up_questions)\n",
    "\n",
    "    assert action in [\"Want to know more\", \"Respond that is certain\"], print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When was the story first published?\\n']\n",
      "['The story seems to involve a person who is reminiscing about someone named Anne and their past experiences together. The protagonist seems to have strong feelings for Anne and is haunted by memories of her.']\n",
      "[['routine had caught up to him, and he had taken off into the woods without purpose or direction\\nand finally he had come to the hill and had climbed it and seen the girl.\\nHer eyes were blue, he saw when he came up to her—as blue as the sky that framed her\\nslender silhouette. Her face was oval and young and soft and sweet. It evoked a déjà vu so\\npoignant that he had to resist an impulse to reach out and touch her wind-kissed cheek; and even', 'that she loved him, that in a few short hours he would see her again. Surely even a run-down\\ntime machine should have no trouble transporting her from the hamlet to the hill.\\nHe arrived there early and sat down on the granite bench and waited for her to come out\\nof the woods and climb the slope. He could feel the hammering of his heart and he knew that his\\nhands were trembling. Day before yesterday I saw a rabbit, and yesterday a deer, and today,\\nyou.', 'The next afternoon she did not show up either. Nor the next. He could neither eat nor\\nsleep. Fishing palled on him. He could no longer read. And all the while, he hated himself—\\nhated himself for behaving like a lovesick schoolboy, for reacting just like any other fool in his\\nforties to a pretty face and a pair of pretty legs. Up until a few days ago he had never even so\\n-8-\\nmuch as looked at another woman, and here in the space of less than a week he had not only', \"long and slender legs. In any event, he got the definite impression that she had somehow stepped\\nout of the past and into the present; and that was odd, because as things turned out, it wasn't the\\npast she had stepped out of, but the future.\\nHe paused some distance behind her, breathing hard from the climb. She had not seen\\nhim yet, and he wondered how he could apprise her of his presence without alarming her. While\", 'she who asked, \"Will you be here tomorrow?\"—though only because she stole the question from\\nhis lips—and the words sang in his ears all the way back through the woods to the cabin and\\nlulled him to sleep after an evening spent with his pipe on the porch.\\nNext afternoon when he climbed the hill it was empty. At first his disappointment\\nnumbed him, and then he thought, “She\\'s late, that\\'s all”. She\\'ll probably show up any minute.', 'from the well-stocked bookcase by the fireplace, he sat down and thumbed through it to\\nAfternoon on a Hill. He read the treasured poem three times, and each time he read it he saw her\\nstanding there in the sun, her hair dancing in the wind, her dress swirling like gentle snow around\\nher long and lovely legs; and a lump came into his throat, and he could not swallow.\\nHe returned the book to the shelf and went out and stood on the rustic porch and filled', \"pronounced.\\nHe began driving into the country Sunday afternoons and visiting the hilltop. The woods\\nwere golden now, and the sky was even bluer than it had been a month ago. For hours he sat on\\nthe granite bench, staring at the spot where she had disappeared. Day before yesterday I saw a\\nrabbit, and yesterday a deer, and today, you.\\nThen, on a rainy night in mid-November, he found the suitcase. It was Anne's, and he\", \"timidly before his desk. It was inconceivable that a mere twenty years later he could be looking\\nforward eagerly to a tryst with an overimaginative girl who was young enough to be his\\ndaughter. Well, he wasn't—not really. He had been momentarily swayed—that was all. For a\\nmoment his emotional equilibrium had deserted him, and he had staggered. Now his feet were\\nback under him where they belonged, and the world had returned to its sane and sensible orbit.\", 'him someday, about Anne\\'s phobia about cameras and how she had refused to have her picture\\ntaken on their wedding day and had gone on refusing ever since, about the grand time the three\\nof them had had on the camping trip they\\'d gone on last summer.\\nWhen he had finished, she said, \"What a wonderful family life you have. Nineteen-sixtyone must be a marvelous year in which to live!\"\\n\"With a time machine at your disposal, you can move here any time you like.\"\\n-6-', \"him when he went to bed. This time he didn't even try to think of Anne; he knew it would do no\\ngood. Instead he lay there in the darkness and played host to whatever random thoughts came\\nalong—and all of them concerned a September hilltop and a girl with dandelion-colored hair.\\nDay before yesterday I saw a rabbit, and yesterday a deer, and today, you.\\nNext morning he drove over to the hamlet and checked at the post office to see if he had\"]]\n"
     ]
    }
   ],
   "source": [
    "# respond\n",
    "print(questions)\n",
    "print(dandelion_girl_0_hop__potential_answer_listxd)\n",
    "print(dandelion_girl_0_hop__gathered_docs_list2d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "template_check_answer = \"\"\"Check the following response to the question is correct or not:, \n",
    "    in the book \"The Dandelion Girl\", \n",
    "    the question is: {question}\n",
    "    the response is: {response}\n",
    "\n",
    "    Action: [\"True\", \"False\"]\n",
    "    repond in the following format:\n",
    "        Action: \n",
    "        Explaination:\n",
    "\"\"\"\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt_check_answer = ChatPromptTemplate.from_template(template_check_answer)\n",
    "\n",
    "chain_check_answer = (\n",
    "    {\"question\": itemgetter(\"question\"), \"response\": itemgetter(\"response\")}\n",
    "    | prompt_check_answer\n",
    "    | model\n",
    "    # | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking_result_list = []\n",
    "checking_TF_list = []\n",
    "checking_explaination_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "for q, potential_answer in zip(questions, dandelion_girl_0_hop__potential_answer_listxd):\n",
    "    response = chain_check_answer.invoke({\"question\":q, \"response\":potential_answer})\n",
    "\n",
    "    resp_parsed = re.split(r\"([\\w \\-\\(\\)>=3]+:)\", response.content)\n",
    "    assert (resp_parsed[1] == \"Action:\" and \n",
    "            resp_parsed[3] == \"Explanation:\" \n",
    "        )\n",
    "\n",
    "    action = resp_parsed[2].strip()\n",
    "    explanation = resp_parsed[4].strip()\n",
    "\n",
    "    checking_result_list.append(response)\n",
    "    checking_TF_list.append(action)\n",
    "    checking_explaination_list.append(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When was the story first published?\\n']\n",
      "['The story seems to involve a person who is reminiscing about someone named Anne and their past experiences together. The protagonist seems to have strong feelings for Anne and is haunted by memories of her.']\n",
      "[['routine had caught up to him, and he had taken off into the woods without purpose or direction\\nand finally he had come to the hill and had climbed it and seen the girl.\\nHer eyes were blue, he saw when he came up to her—as blue as the sky that framed her\\nslender silhouette. Her face was oval and young and soft and sweet. It evoked a déjà vu so\\npoignant that he had to resist an impulse to reach out and touch her wind-kissed cheek; and even', 'that she loved him, that in a few short hours he would see her again. Surely even a run-down\\ntime machine should have no trouble transporting her from the hamlet to the hill.\\nHe arrived there early and sat down on the granite bench and waited for her to come out\\nof the woods and climb the slope. He could feel the hammering of his heart and he knew that his\\nhands were trembling. Day before yesterday I saw a rabbit, and yesterday a deer, and today,\\nyou.', 'The next afternoon she did not show up either. Nor the next. He could neither eat nor\\nsleep. Fishing palled on him. He could no longer read. And all the while, he hated himself—\\nhated himself for behaving like a lovesick schoolboy, for reacting just like any other fool in his\\nforties to a pretty face and a pair of pretty legs. Up until a few days ago he had never even so\\n-8-\\nmuch as looked at another woman, and here in the space of less than a week he had not only', \"long and slender legs. In any event, he got the definite impression that she had somehow stepped\\nout of the past and into the present; and that was odd, because as things turned out, it wasn't the\\npast she had stepped out of, but the future.\\nHe paused some distance behind her, breathing hard from the climb. She had not seen\\nhim yet, and he wondered how he could apprise her of his presence without alarming her. While\", 'she who asked, \"Will you be here tomorrow?\"—though only because she stole the question from\\nhis lips—and the words sang in his ears all the way back through the woods to the cabin and\\nlulled him to sleep after an evening spent with his pipe on the porch.\\nNext afternoon when he climbed the hill it was empty. At first his disappointment\\nnumbed him, and then he thought, “She\\'s late, that\\'s all”. She\\'ll probably show up any minute.', 'from the well-stocked bookcase by the fireplace, he sat down and thumbed through it to\\nAfternoon on a Hill. He read the treasured poem three times, and each time he read it he saw her\\nstanding there in the sun, her hair dancing in the wind, her dress swirling like gentle snow around\\nher long and lovely legs; and a lump came into his throat, and he could not swallow.\\nHe returned the book to the shelf and went out and stood on the rustic porch and filled', \"pronounced.\\nHe began driving into the country Sunday afternoons and visiting the hilltop. The woods\\nwere golden now, and the sky was even bluer than it had been a month ago. For hours he sat on\\nthe granite bench, staring at the spot where she had disappeared. Day before yesterday I saw a\\nrabbit, and yesterday a deer, and today, you.\\nThen, on a rainy night in mid-November, he found the suitcase. It was Anne's, and he\", \"timidly before his desk. It was inconceivable that a mere twenty years later he could be looking\\nforward eagerly to a tryst with an overimaginative girl who was young enough to be his\\ndaughter. Well, he wasn't—not really. He had been momentarily swayed—that was all. For a\\nmoment his emotional equilibrium had deserted him, and he had staggered. Now his feet were\\nback under him where they belonged, and the world had returned to its sane and sensible orbit.\", 'him someday, about Anne\\'s phobia about cameras and how she had refused to have her picture\\ntaken on their wedding day and had gone on refusing ever since, about the grand time the three\\nof them had had on the camping trip they\\'d gone on last summer.\\nWhen he had finished, she said, \"What a wonderful family life you have. Nineteen-sixtyone must be a marvelous year in which to live!\"\\n\"With a time machine at your disposal, you can move here any time you like.\"\\n-6-', \"him when he went to bed. This time he didn't even try to think of Anne; he knew it would do no\\ngood. Instead he lay there in the darkness and played host to whatever random thoughts came\\nalong—and all of them concerned a September hilltop and a girl with dandelion-colored hair.\\nDay before yesterday I saw a rabbit, and yesterday a deer, and today, you.\\nNext morning he drove over to the hamlet and checked at the post office to see if he had\"]]\n",
      "['False']\n",
      "['The response does not answer the question of when the story \"The Dandelion Girl\" was first published. It provides information about the plot and the protagonist\\'s feelings, but it does not address the publication date.']\n",
      "\n",
      "\n",
      "routine had caught up to him, and he had taken off into the woods without purpose or direction\n",
      "and finally he had come to the hill and had climbed it and seen the girl.\n",
      "Her eyes were blue, he saw when he came up to her—as blue as the sky that framed her\n",
      "slender silhouette. Her face was oval and young and soft and sweet. It evoked a déjà vu so\n",
      "poignant that he had to resist an impulse to reach out and touch her wind-kissed cheek; and even\n",
      "that she loved him, that in a few short hours he would see her again. Surely even a run-down\n",
      "time machine should have no trouble transporting her from the hamlet to the hill.\n",
      "He arrived there early and sat down on the granite bench and waited for her to come out\n",
      "of the woods and climb the slope. He could feel the hammering of his heart and he knew that his\n",
      "hands were trembling. Day before yesterday I saw a rabbit, and yesterday a deer, and today,\n",
      "you.\n",
      "The next afternoon she did not show up either. Nor the next. He could neither eat nor\n",
      "sleep. Fishing palled on him. He could no longer read. And all the while, he hated himself—\n",
      "hated himself for behaving like a lovesick schoolboy, for reacting just like any other fool in his\n",
      "forties to a pretty face and a pair of pretty legs. Up until a few days ago he had never even so\n",
      "-8-\n",
      "much as looked at another woman, and here in the space of less than a week he had not only\n",
      "long and slender legs. In any event, he got the definite impression that she had somehow stepped\n",
      "out of the past and into the present; and that was odd, because as things turned out, it wasn't the\n",
      "past she had stepped out of, but the future.\n",
      "He paused some distance behind her, breathing hard from the climb. She had not seen\n",
      "him yet, and he wondered how he could apprise her of his presence without alarming her. While\n",
      "she who asked, \"Will you be here tomorrow?\"—though only because she stole the question from\n",
      "his lips—and the words sang in his ears all the way back through the woods to the cabin and\n",
      "lulled him to sleep after an evening spent with his pipe on the porch.\n",
      "Next afternoon when he climbed the hill it was empty. At first his disappointment\n",
      "numbed him, and then he thought, “She's late, that's all”. She'll probably show up any minute.\n",
      "from the well-stocked bookcase by the fireplace, he sat down and thumbed through it to\n",
      "Afternoon on a Hill. He read the treasured poem three times, and each time he read it he saw her\n",
      "standing there in the sun, her hair dancing in the wind, her dress swirling like gentle snow around\n",
      "her long and lovely legs; and a lump came into his throat, and he could not swallow.\n",
      "He returned the book to the shelf and went out and stood on the rustic porch and filled\n",
      "pronounced.\n",
      "He began driving into the country Sunday afternoons and visiting the hilltop. The woods\n",
      "were golden now, and the sky was even bluer than it had been a month ago. For hours he sat on\n",
      "the granite bench, staring at the spot where she had disappeared. Day before yesterday I saw a\n",
      "rabbit, and yesterday a deer, and today, you.\n",
      "Then, on a rainy night in mid-November, he found the suitcase. It was Anne's, and he\n",
      "timidly before his desk. It was inconceivable that a mere twenty years later he could be looking\n",
      "forward eagerly to a tryst with an overimaginative girl who was young enough to be his\n",
      "daughter. Well, he wasn't—not really. He had been momentarily swayed—that was all. For a\n",
      "moment his emotional equilibrium had deserted him, and he had staggered. Now his feet were\n",
      "back under him where they belonged, and the world had returned to its sane and sensible orbit.\n",
      "him someday, about Anne's phobia about cameras and how she had refused to have her picture\n",
      "taken on their wedding day and had gone on refusing ever since, about the grand time the three\n",
      "of them had had on the camping trip they'd gone on last summer.\n",
      "When he had finished, she said, \"What a wonderful family life you have. Nineteen-sixtyone must be a marvelous year in which to live!\"\n",
      "\"With a time machine at your disposal, you can move here any time you like.\"\n",
      "-6-\n",
      "him when he went to bed. This time he didn't even try to think of Anne; he knew it would do no\n",
      "good. Instead he lay there in the darkness and played host to whatever random thoughts came\n",
      "along—and all of them concerned a September hilltop and a girl with dandelion-colored hair.\n",
      "Day before yesterday I saw a rabbit, and yesterday a deer, and today, you.\n",
      "Next morning he drove over to the hamlet and checked at the post office to see if he had\n"
     ]
    }
   ],
   "source": [
    "print(questions)\n",
    "print(dandelion_girl_0_hop__potential_answer_listxd)\n",
    "print(dandelion_girl_0_hop__gathered_docs_list2d)\n",
    "print(checking_TF_list)\n",
    "print(checking_explaination_list)\n",
    "\n",
    "for docs in dandelion_girl_0_hop__gathered_docs_list2d:\n",
    "    print()\n",
    "    print()\n",
    "    for doc in docs:\n",
    "        print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_llm = OpenAI(n=4, best_of=4)\n",
    "# embeddings = HypotheticalDocumentEmbedder.from_llm(\n",
    "#     multi_llm, base_embeddings, \"web_search\"\n",
    "# )\n",
    "# result = embeddings.embed_query(\"Where is the Taj Mahal?\")\n",
    "\n",
    "# multi_response\n",
    "# results = multi_llm.generate([\"Where is the Taj Mahal?\"])\n",
    "# print(results)\n",
    "\n",
    "# chain_tmp = (RunnablePassthrough() | multi_llm)\n",
    "# print(chain_tmp.invoke(\"Where is the Taj Mahal?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 1.62k/1.62k [00:00<?, ?B/s]\n",
      "c:\\Users\\benve\\anaconda3\\envs\\py310\\lib\\site-packages\\huggingface_hub\\file_download.py:137: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\benve\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading tokenizer.model: 100%|██████████| 500k/500k [00:00<00:00, 6.21MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 414/414 [00:00<?, ?B/s] \n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.84M/1.84M [00:00<00:00, 17.3MB/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Could not infer framework from class <class 'langchain.chat_models.openai.ChatOpenAI'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\LocalLaptop\\BU\\courses\\2023-Fall\\CS505\\HW\\Project\\langchain_QA.ipynb Cell 25\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39mfrom_pretrained(model_path, use_fast\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# model = AutoModelForCausalLM.from_pretrained(\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#     model_path,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m#     load_in_4bit=True,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#     torch_dtype=torch.float16,\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#     device_map='auto'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# )\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m pipeline\u001b[39m=\u001b[39mtransformers\u001b[39m.\u001b[39;49mpipeline(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mtext-generation\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39;49mtokenizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mbfloat16,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     device_map\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     max_length\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     top_k\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     num_return_sequences\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     eos_token_id\u001b[39m=\u001b[39;49mtokenizer\u001b[39m.\u001b[39;49meos_token_id\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X31sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m llm\u001b[39m=\u001b[39mHuggingFacePipeline(pipeline\u001b[39m=\u001b[39mpipeline, model_kwargs\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mtemperature\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m0.7\u001b[39m})\n",
      "File \u001b[1;32mc:\\Users\\benve\\anaconda3\\envs\\py310\\lib\\site-packages\\transformers\\pipelines\\__init__.py:870\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 870\u001b[0m     framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    871\u001b[0m         model,\n\u001b[0;32m    872\u001b[0m         model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[0;32m    873\u001b[0m         config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    874\u001b[0m         framework\u001b[39m=\u001b[39mframework,\n\u001b[0;32m    875\u001b[0m         task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    876\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    877\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    878\u001b[0m     )\n\u001b[0;32m    880\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    881\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
      "File \u001b[1;32mc:\\Users\\benve\\anaconda3\\envs\\py310\\lib\\site-packages\\transformers\\pipelines\\base.py:287\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    283\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not load model \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m with any of the following classes: \u001b[39m\u001b[39m{\u001b[39;00mclass_tuple\u001b[39m}\u001b[39;00m\u001b[39m. See the original errors:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m         )\n\u001b[0;32m    286\u001b[0m \u001b[39mif\u001b[39;00m framework \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m     framework \u001b[39m=\u001b[39m infer_framework(model\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m)\n\u001b[0;32m    288\u001b[0m \u001b[39mreturn\u001b[39;00m framework, model\n",
      "File \u001b[1;32mc:\\Users\\benve\\anaconda3\\envs\\py310\\lib\\site-packages\\transformers\\utils\\generic.py:690\u001b[0m, in \u001b[0;36minfer_framework\u001b[1;34m(model_class)\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mflax\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 690\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCould not infer framework from class \u001b[39m\u001b[39m{\u001b[39;00mmodel_class\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not infer framework from class <class 'langchain.chat_models.openai.ChatOpenAI'>."
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer\n",
    "from langchain.chains import ConversationChain\n",
    "import transformers\n",
    "import torch\n",
    "import warnings\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "\n",
    "# model_path = '/mnt/h/Chinese-Llama-2-7b-4bit'\n",
    "model_path = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_path,\n",
    "#     load_in_4bit=True,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     device_map='auto'\n",
    "# )\n",
    "\n",
    "pipeline=transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    "    max_length=1000,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "llm=HuggingFacePipeline(pipeline=pipeline, model_kwargs={'temperature':0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = \"\"\"<s>[INST] <<SYS>>\n",
    "# {{ You are a helpful AI Assistant}}<<SYS>>\n",
    "# ###\n",
    "\n",
    "# Previous Conversation:\n",
    "# '''\n",
    "# {history}\n",
    "# '''\n",
    "\n",
    "# {{{input}}}[/INST]\n",
    "\n",
    "# \"\"\"\n",
    "# prompt = PromptTemplate(template=prompt_template, input_variables=['input', 'history'])\n",
    "\n",
    "\n",
    "\n",
    "# chain = ConversationChain(llm=llm, prompt=prompt)\n",
    "# chain.run(\"What is the capital Of India?\")\n",
    "\n",
    "# memory = ConversationBufferWindowMemory(k=5)\n",
    "\n",
    "# chain = ConversationChain(\n",
    "#     llm=llm,\n",
    "#     prompt=prompt,\n",
    "#     memory=memory\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer,\\\\\n",
    "just say that you don't know, don't try to make up an answer. \n",
    "\n",
    "{context}\n",
    "\n",
    "{history}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"context\", \"question\"], template=template)\n",
    "memory = ConversationBufferMemory(input_key='question', memory_key='history')\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=db.as_retriever(), llm=llm)\n",
    "# retriever_from_llm = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever_from_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retri_docs = compression_retriever.get_relevant_documents('主人公はだれですか？')\n",
    "# print(retri_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Pipe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\LocalLaptop\\BU\\courses\\2023-Fall\\CS505\\HW\\Project\\langchain_QA.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mPipe\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstatistics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m@Pipe\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/LocalLaptop/BU/courses/2023-Fall/CS505/HW/Project/langchain_QA.ipynb#X46sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrunning_average\u001b[39m(iterable, width):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Pipe'"
     ]
    }
   ],
   "source": [
    "# import Pipe\n",
    "# from statistics import mean\n",
    "\n",
    "# @Pipe\n",
    "# def running_average(iterable, width):\n",
    "#     items = deque(maxlen=width)\n",
    "#     for item in iterable:\n",
    "#         items.append(item)\n",
    "#         yield mean(items)\n",
    "\n",
    "# list(range(20) | running_average(width=2))\n",
    "# list(range(20) | running_average(width=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"what is {a} + {b}\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt | model\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"foo\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"foo\"), \"text2\": itemgetter(\"bar\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    # | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='what is 5 + 25')]\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"foo\": \"hello\", \"bar\": \"world\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
